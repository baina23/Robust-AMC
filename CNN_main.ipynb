{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bb26c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "import os, random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from models import CNN\n",
    "from models import RNN\n",
    "from models import AUTOENCODER\n",
    "from attacks import gradient_wrt_data\n",
    "from attacks import FGSM_Linf_attack\n",
    "from attacks import FGSM_L2_attack\n",
    "from utilities import *\n",
    "\n",
    "\n",
    "#from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.interpolate import make_interp_spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b10b5de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Current Device:  cuda\n",
      "Quadro RTX 6000\n"
     ]
    }
   ],
   "source": [
    "seed = 5\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"  # specify which GPU(s) to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Current Device: \", device)\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "21d9c1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"RML2016.10b.dat\"\n",
    "snrs, mods, X, labels = process_data(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1d28b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_model = \"CNN\"\n",
    "\n",
    "#subsample = 1\n",
    "subsample = 2\n",
    "# subsample = 4\n",
    "#subsample = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ea8f1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([480000, 1, 2, 64])\n",
      "torch.Size([120000, 1, 2, 64])\n",
      "torch.Size([480000])\n",
      "torch.Size([120000])\n"
     ]
    }
   ],
   "source": [
    "x_train0, x_test0, y_train, y_test, test_labels, test_idx = train_test_split(X, labels, mods, NN = curr_model)\n",
    "\n",
    "#####################################################################\n",
    "x_train = x_train0[:,:,:,::subsample]\n",
    "x_test = x_test0[:,:,:,::subsample]\n",
    "####################################################################\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8b93037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_model == \"CNN\" :\n",
    "    batch_size = 256    \n",
    "    if subsample == 1 : \n",
    "        model = CNN(input_size = 128).to(device = device)\n",
    "        model_checkpoint = \"CNN_base.pt\"\n",
    "    if subsample == 2 :\n",
    "        model = CNN(input_size = 64).to(device = device)\n",
    "        model_checkpoint = \"CNN_base_sub12.pt\"\n",
    "    if subsample == 4 :\n",
    "        model = CNN(input_size = 32).to(device = device)\n",
    "        model_checkpoint = \"CNN_base_sub14.pt\"\n",
    "    if subsample == 8 :\n",
    "        model = CNN(input_size = 16).to(device = device)\n",
    "        model_checkpoint = \"CNN_base_sub18.pt\"\n",
    "\n",
    "num_epochs = 100\n",
    "criterion  = nn.CrossEntropyLoss()\n",
    "optimizer  = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, y_train.type(torch.LongTensor))\n",
    "test_dataset  = TensorDataset(x_test,  y_test.type(torch.LongTensor))\n",
    "\n",
    "TrainLoader = DataLoader(train_dataset, batch_size = batch_size, \n",
    "                         shuffle = False)\n",
    "TestLoader  = DataLoader(test_dataset,  batch_size = batch_size, \n",
    "                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c66f8",
   "metadata": {},
   "source": [
    "### Baseline Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs   = 100\n",
    "best_val_acc = 0.\n",
    "criterion    = nn.CrossEntropyLoss()\n",
    "optimizer    = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(num_epochs) :\n",
    "    model.train()\n",
    "    train_epoch_loss = 0.\n",
    "    train_epoch_acc  = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(TrainLoader) :\n",
    "        data   = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss    = criterion(outputs, labels)\n",
    "        acc     = evaluate_accuracy(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.item()\n",
    "        train_epoch_acc  += acc.item()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0.\n",
    "        val_epoch_acc  = 0.\n",
    "        \n",
    "        for X_val_batch, y_val_batch in TestLoader :\n",
    "            X_val_batch = X_val_batch.to(device)\n",
    "            y_val_batch = y_val_batch.to(device)\n",
    "            \n",
    "            y_val_pred = model(X_val_batch)\n",
    "            \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc  = evaluate_accuracy(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc  += val_acc.item()\n",
    "    \n",
    "    avg_train_loss = float(train_epoch_loss) / len(TrainLoader)\n",
    "    avg_train_acc  = float(train_epoch_acc) / len(TrainLoader)\n",
    "    avg_val_loss   = float(val_epoch_loss) / len(TestLoader)\n",
    "    avg_val_acc    = float(val_epoch_acc) / len(TestLoader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: | Train Acc: {avg_train_acc:.3f} | Test Acc: {avg_val_acc:.3f}')\n",
    "    \n",
    "    if avg_val_acc > best_val_acc :\n",
    "        print(\"Saving Model Checkpoint......\")\n",
    "        best_val_acc = avg_val_acc\n",
    "        torch.save(model.state_dict(), model_checkpoint)\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de8925",
   "metadata": {},
   "source": [
    "### Baseline Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efe6a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_net1 = CNN()\n",
    "cnn_net2 = CNN(input_size=64)\n",
    "cnn_net8 = CNN(input_size=16)\n",
    "cnn_net1.load_state_dict(torch.load(\"CNN_base.pt\"))\n",
    "cnn_net2.load_state_dict(torch.load(\"CNN_base_sub12.pt\"))\n",
    "cnn_net8.load_state_dict(torch.load(\"CNN_base_sub18.pt\"))\n",
    "cnn_net1 = cnn_net1.to(device)\n",
    "cnn_net2 = cnn_net2.to(device)\n",
    "cnn_net8 = cnn_net8.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_acc1, cnn_loss1, y_preds1 = evaluate_model(cnn_net1, TestLoader, device)\n",
    "y_test_np = y_test.cpu().numpy()\n",
    "print(\"CNN_base Accuracy = %.4f\" % cnn_acc1)\n",
    "# print(type(y_preds))\n",
    "# print(type(y_test_np))\n",
    "# print(y_preds.shape)\n",
    "# print(y_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_tests = y_test.cpu().numpy(), \n",
    "                      y_preds = y_preds, mods = mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d186fe90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train2, x_test2 = x_train0[:,:,:,::2], x_test0[:,:,:,::2]\n",
    "x_train8, x_test8 = x_train0[:,:,:,::8], x_test0[:,:,:,::8]\n",
    "acc_dict1 = plot_snr_accuracy(cnn_net1, x_test0, labels, test_labels, test_idx, snrs, mods, device)\n",
    "plt.plot(label = 'No Samples')\n",
    "acc_dict2 = plot_snr_accuracy(cnn_net2, x_test2, labels, test_labels, test_idx, snrs, mods, device)\n",
    "plt.plot(label = '1/2 Samples')\n",
    "acc_dict8 = plot_snr_accuracy(cnn_net8, x_test8, labels, test_labels, test_idx, snrs, mods, device)\n",
    "plt.plot(label = '1/8 Samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3886a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe7c593",
   "metadata": {},
   "source": [
    "### Adversarial Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4bd4ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPS for FGSM attack\n",
    "curr_attack = \"FGSM_Linfinity\"\n",
    "eps_values = np.array([0.000, 0.001, 0.002, 0.003, 0.005, 0.007, \n",
    "                       0.010, 0.020, 0.030])\n",
    "fgsm_acc = np.zeros(len(eps_values))\n",
    "fgsm_art_acc = np.zeros(len(eps_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9617d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPS for FGM L2 attack\n",
    "curr_attack = \"FGSM_L2\"\n",
    "eps_values = np.array([0.00, 0.01, 0.02, 0.04, 0.06, 0.08, 0.10, \n",
    "                       0.20, 0.30, 0.40, 0.50])\n",
    "fgm_acc = np.zeros(len(eps_values))\n",
    "fgm_art_acc = np.zeros(len(eps_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85e4a6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current ATK_EPS Index = 1\n",
      "Current ATK_EPS Index = 2\n",
      "Current ATK_EPS Index = 3\n",
      "Current ATK_EPS Index = 4\n",
      "Current ATK_EPS Index = 5\n",
      "Current ATK_EPS Index = 6\n",
      "Current ATK_EPS Index = 7\n",
      "Current ATK_EPS Index = 8\n",
      "Current ATK_EPS Index = 9\n",
      "Current ATK_EPS Index = 10\n",
      "Current ATK_EPS Index = 11\n",
      "Attack Done!\n",
      "[0.873975   0.67265    0.60540833 0.5442     0.50801667 0.47680833\n",
      " 0.44433333 0.28264167 0.19341667 0.164425   0.15573333]\n"
     ]
    }
   ],
   "source": [
    "whitebox = CNN(input_size=64)\n",
    "\n",
    "#whitebox.load_state_dict(torch.load(\"CNN_base_sub12.pt\"))\n",
    "\n",
    "#whitebox.load_state_dict(torch.load(\"CNN_FGSM_ART_sub12.pt\"))\n",
    "whitebox.load_state_dict(torch.load(\"CNN_FGML2_ART_sub12.pt\"))\n",
    "\n",
    "whitebox = whitebox.to(device)\n",
    "whitebox.eval()\n",
    "for i in range(len(eps_values)) :\n",
    "    print(\"Current ATK_EPS Index = \" + str(i + 1))\n",
    "    ATK_EPS   = eps_values[i]\n",
    "    whitebox_correct = 0\n",
    "    running_total    = 0\n",
    "    for batch_idx, (data, labels) in enumerate(TestLoader) :\n",
    "        data   = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #################################################################\n",
    "        if curr_attack == \"FGSM_Linfinity\" :\n",
    "            # Fast Gradient Sign Method (FGSM) L-infinity Norm Attack\n",
    "            adv_data = FGSM_Linf_attack(whitebox, device, data, \n",
    "                                        labels, eps = ATK_EPS)\n",
    "        if curr_attack == \"FGSM_L2\" :\n",
    "            # Fast Gradient Sign Method (FGSM) L-2 Norm Attack\n",
    "            adv_data = FGSM_L2_attack(whitebox, device, data, labels, \n",
    "                                      eps = ATK_EPS)\n",
    "        #################################################################\n",
    "        \n",
    "        # Compute accuracy on perturbed data\n",
    "        with torch.no_grad() :\n",
    "            whitebox_outputs  = whitebox(adv_data)\n",
    "            _, whitebox_preds = whitebox_outputs.max(1)\n",
    "            whitebox_correct += whitebox_preds.eq(labels).sum().item()\n",
    "            running_total    += labels.size(0)\n",
    "    \n",
    "    whitebox_acc = float(whitebox_correct) / running_total\n",
    "    \n",
    "    if curr_attack == \"FGSM_Linfinity\" :\n",
    "        #fgsm_acc[i] = whitebox_acc\n",
    "        fgsm_art_acc[i] = whitebox_acc\n",
    "    if curr_attack == \"FGSM_L2\" :\n",
    "        #fgm_acc[i] = whitebox_acc\n",
    "        fgm_art_acc[i] = whitebox_acc\n",
    "\n",
    "print(\"Attack Done!\")\n",
    "print(fgm_art_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9b68cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88895833 0.5662     0.46883333 0.36074167 0.195175   0.13670833\n",
      " 0.12288333 0.09525    0.09901667]\n"
     ]
    }
   ],
   "source": [
    "print(fgsm_art_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb69fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_summary (base_acc, art_acc, detect_acc, eps_values, eps_values_T) :\n",
    "    figure, axis = plt.subplots()\n",
    "    # base_Spline = make_interp_spline(eps_values, base_acc)\n",
    "    # art_Spline = make_interp_spline(eps_values, art_acc)\n",
    "    detect_Spline = make_interp_spline(eps_values_T, detect_acc)\n",
    "    # X0_ = np.linspace(eps_values.min(),eps_values.max(),20)\n",
    "    X1_ = np.linspace(eps_values_T.min(),eps_values_T.max(),20)\n",
    "    # base = base_Spline(X0_)\n",
    "    # art = art_Spline(X0_)\n",
    "    detect = detect_Spline(X1_)\n",
    "\n",
    "    axis.plot(eps_values, base_acc,   label = \"BASE\", linewidth = 3)\n",
    "    axis.plot(eps_values, art_acc,    label = \"ART\",  linewidth = 3)\n",
    "    axis.plot(X1_, detect, label = \"DECT\", linewidth = 3)\n",
    "    axis.set_xlabel(\"EPS\", fontsize = 12)\n",
    "    axis.set_ylabel(\"ACC\", fontsize = 12)\n",
    "    axis.set_title(\"No Subsampling\", fontsize = 12)\n",
    "    axis.grid()\n",
    "    figure.set_size_inches(6, 4)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.legend(fontsize = 12)\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d49610",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_values_0 = np.array([0.000, 0.001, 0.002, 0.003, 0.005, 0.007, \n",
    "                       0.010, 0.020, 0.030])\n",
    "\n",
    "fgsm_acc = np.array([0.90775833, 0.52973333, 0.35055833, 0.248125, 0.14935, \n",
    "                     0.12344167, 0.10616667, 0.08269167, 0.09775833])\n",
    "\n",
    "fgsm_art_acc = np.array([0.89946667, 0.66180833, 0.64145833, 0.592725,   0.49783333, 0.47271667,\n",
    "                        0.42183333, 0.127275, 0.08095])\n",
    "\n",
    "eps_values_T0 = np.array([0, 0.001, 0.002, 0.003, 0.005, 0.007, 0.010, 0.012, 0.017, 0.022, \n",
    "                        0.027, 0.030])\n",
    "\n",
    "detect0_acc = np.array([0, 0.007266666666666667, 0.012493333333333334, 0.03602, 0.2676733333333333, \n",
    "                       0.5352466666666666, 0.7463066666666667, 0.8421333333333333, 0.9984266666666667, 1.0, 1.0, 1.0])\n",
    "\n",
    "eps_values_1 = np.array([0.00, 0.01, 0.02, 0.04, 0.06, 0.08, 0.10, \n",
    "                       0.20, 0.30, 0.40, 0.50])\n",
    "\n",
    "fgm_acc = np.array([0.90775833, 0.59928333, 0.49648333, 0.28905833, \n",
    "                    0.22471667, 0.20176667, 0.19169167, 0.16296667, 0.13998333, \n",
    "                    0.12625833, 0.11841667])\n",
    "\n",
    "fgm_art_acc = np.array([0.90353333, 0.71053333, 0.65710833, 0.601575,   0.57029167, 0.54256667,\n",
    "                        0.51161667, 0.28706667, 0.16754167, 0.12459167, 0.11054167])\n",
    "\n",
    "detect1_acc = np.array([0.007655555555555555, 0.026455555555555555, 0.21103333333333332, 0.4010888888888889, 0.5513888888888889, \n",
    "                        0.6603222222222223, 0.7446, 0.8098666666666666, 0.8561555555555556, 0.8914888888888889, 0.9173222222222223])\n",
    "\n",
    "eps_values_T1 = np.array([0.00, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, \n",
    "                       0.35, 0.4, 0.45, 0.50])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_values_0 = np.array([0.000, 0.001, 0.002, 0.003, 0.005, 0.007, \n",
    "                       0.010, 0.020, 0.030])\n",
    "\n",
    "fgsm_acc = np.array([0.88895833, 0.5662,     0.46883333, 0.36074167, 0.195175,   0.13670833,\n",
    "                    0.12288333, 0.09525,    0.09901667])\n",
    "\n",
    "fgsm_art_acc = np.array([0.873,      0.62846667, 0.550975,   0.4847,     0.37970833, 0.31566667,\n",
    "                    0.27445833, 0.11316667, 0.09768333])\n",
    "\n",
    "eps_values_T0 = np.array([0, 0.001, 0.002, 0.003, 0.005, 0.007, 0.010, 0.012, 0.017, 0.022, \n",
    "                        0.027, 0.030])\n",
    "\n",
    "detect0_acc = np.array([0, 0.007266666666666667, 0.012493333333333334, 0.03602, 0.2676733333333333, \n",
    "                       0.5352466666666666, 0.7463066666666667, 0.8421333333333333, 0.9984266666666667, 1.0, 1.0, 1.0])\n",
    "\n",
    "eps_values_1 = np.array([0.00, 0.01, 0.02, 0.04, 0.06, 0.08, 0.10, \n",
    "                       0.20, 0.30, 0.40, 0.50])\n",
    "\n",
    "fgm_acc = np.array([0.88895833, 0.57163333, 0.41284167, 0.257725,   0.20806667, 0.17810833,\n",
    "                    0.15861667, 0.12185,    0.11030833, 0.106225,   0.1036    ])\n",
    "\n",
    "fgm_art_acc = np.array([0.873975,   0.67265,    0.60540833,  0.5442,     0.50801667, 0.47680833,\n",
    "                        0.44433333, 0.28264167, 0.19341667, 0.164425,   0.15573333])\n",
    "\n",
    "detect1_acc = np.array([0.007655555555555555, 0.026455555555555555, 0.21103333333333332, 0.4010888888888889, 0.5513888888888889, \n",
    "                        0.6603222222222223, 0.7446, 0.8098666666666666, 0.8561555555555556, 0.8914888888888889, 0.9173222222222223])\n",
    "\n",
    "eps_values_T1 = np.array([0.00, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, \n",
    "                       0.35, 0.4, 0.45, 0.50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_summary(fgsm_acc, fgsm_art_acc, detect0_acc, eps_values_0, eps_values_T0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22068367",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_summary(fgm_acc, fgm_art_acc, detect1_acc, eps_values_1, eps_values_T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4bcffe",
   "metadata": {},
   "source": [
    "### Adversarial Retraining (Mitigation) & Manifold Learning (Detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1df5096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: | Train Acc: 51.709 | Test Acc: 86.966\n",
      "Saving Model Checkpoint......\n",
      "Epoch 2: | Train Acc: 55.917 | Test Acc: 86.891\n",
      "Epoch 3: | Train Acc: 56.921 | Test Acc: 87.064\n",
      "Saving Model Checkpoint......\n",
      "Epoch 4: | Train Acc: 57.379 | Test Acc: 87.002\n",
      "Epoch 5: | Train Acc: 57.721 | Test Acc: 87.384\n",
      "Saving Model Checkpoint......\n",
      "Adversarial Retraining Complete!\n"
     ]
    }
   ],
   "source": [
    "model = CNN(input_size = 64)\n",
    "model.load_state_dict(torch.load(\"CNN_base_sub12.pt\"))\n",
    "model = model.to(device)\n",
    "#model_checkpoint = \"CNN_FGSM_ART_sub12.pt\"\n",
    "model_checkpoint = \"CNN_FGML2_ART_sub12.pt\"\n",
    "\n",
    "num_epochs   = 5\n",
    "best_val_acc = 0.\n",
    "criterion    = nn.CrossEntropyLoss()\n",
    "optimizer    = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(num_epochs) :\n",
    "    model.train()\n",
    "    train_epoch_loss = 0.\n",
    "    train_epoch_acc  = 0.\n",
    "    for batch_idx, (data, labels) in enumerate(TrainLoader) :\n",
    "        data   = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # #######################################################################\n",
    "        # # FGSM L-infinity Adversarial Retraining\n",
    "        # adv1_data = FGSM_Linf_attack(model, device, data, labels, eps = 0.001)\n",
    "        # adv2_data = FGSM_Linf_attack(model, device, data, labels, eps = 0.002)\n",
    "        # adv3_data = FGSM_Linf_attack(model, device, data, labels, eps = 0.003)\n",
    "        # adv4_data = FGSM_Linf_attack(model, device, data, labels, eps = 0.005)\n",
    "        # adv5_data = FGSM_Linf_attack(model, device, data, labels, eps = 0.007)\n",
    "        # adv6_data = FGSM_Linf_attack(model, device, data, labels, eps = 0.010)\n",
    "        \n",
    "        # adjdata = torch.vstack((adv1_data, adv2_data, adv3_data, \n",
    "        #                         adv4_data, adv5_data, adv6_data))\n",
    "        # adjlabels = torch.cat((labels, labels, labels, \n",
    "        #                        labels, labels, labels))\n",
    "        \n",
    "        # outputs = model(adjdata)\n",
    "        # loss = criterion(outputs, adjlabels)\n",
    "        # acc = evaluate_accuracy(outputs, adjlabels)\n",
    "        # #######################################################################\n",
    "        \n",
    "        #######################################################################\n",
    "        # FGSM L-2 Adversarial Retraining\n",
    "        adv1_data = FGSM_L2_attack(model, device, data, labels, eps = 0.01)\n",
    "        adv2_data = FGSM_L2_attack(model, device, data, labels, eps = 0.02)\n",
    "        adv3_data = FGSM_L2_attack(model, device, data, labels, eps = 0.04)\n",
    "        adv4_data = FGSM_L2_attack(model, device, data, labels, eps = 0.06)\n",
    "        adv5_data = FGSM_L2_attack(model, device, data, labels, eps = 0.08)\n",
    "        adv6_data = FGSM_L2_attack(model, device, data, labels, eps = 0.10)\n",
    "        \n",
    "        adjdata = torch.vstack((adv1_data, adv2_data, adv3_data, \n",
    "                                adv4_data, adv5_data, adv6_data))\n",
    "        adjlabels = torch.cat((labels, labels, labels, \n",
    "                               labels, labels, labels))\n",
    "        \n",
    "        outputs = model(adjdata)\n",
    "        loss = criterion(outputs, adjlabels)\n",
    "        acc = evaluate_accuracy(outputs, adjlabels)\n",
    "        #######################################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.item()\n",
    "        train_epoch_acc  += acc.item()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0.\n",
    "        val_epoch_acc  = 0.\n",
    "        \n",
    "        for X_val_batch, y_val_batch in TestLoader :\n",
    "            X_val_batch = X_val_batch.to(device)\n",
    "            y_val_batch = y_val_batch.to(device)\n",
    "            \n",
    "            y_val_pred = model(X_val_batch)\n",
    "            \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc  = evaluate_accuracy(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc  += val_acc.item()\n",
    "    \n",
    "    avg_train_loss = float(train_epoch_loss) / len(TrainLoader)\n",
    "    avg_train_acc  = float(train_epoch_acc) / len(TrainLoader)\n",
    "    avg_val_loss   = float(val_epoch_loss) / len(TestLoader)\n",
    "    avg_val_acc    = float(val_epoch_acc) / len(TestLoader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: | Train Acc: {avg_train_acc:.3f} | Test Acc: {avg_val_acc:.3f}')\n",
    "    \n",
    "    #torch.save(model.state_dict(), model_checkpoint)\n",
    "    \n",
    "    if avg_val_acc > best_val_acc :\n",
    "        print(\"Saving Model Checkpoint......\")\n",
    "        best_val_acc = avg_val_acc\n",
    "        torch.save(model.state_dict(), model_checkpoint)\n",
    "\n",
    "print(\"Adversarial Retraining Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbe247d",
   "metadata": {},
   "source": [
    "### Autoencoder Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30353adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AUTOENCODER()\n",
    "model.to(device)\n",
    "model_checkpoint = \"AUTOENCODER.pt\"\n",
    "\n",
    "num_epochs = 100\n",
    "criterion  = nn.MSELoss()\n",
    "optimizer  = optim.SGD(model.parameters(), lr = 0.001)\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = TensorDataset(x_train, x_train)\n",
    "test_dataset  = TensorDataset(x_test,  x_test)\n",
    "\n",
    "TrainLoader = DataLoader(train_dataset, batch_size = batch_size, \n",
    "                         shuffle = False)\n",
    "TestLoader  = DataLoader(test_dataset,  batch_size = batch_size, \n",
    "                         shuffle = False)\n",
    "\n",
    "best_val_loss = 1.\n",
    "\n",
    "for epoch in range(num_epochs) :\n",
    "    model.train()\n",
    "    train_epoch_loss = 0.\n",
    "    for batch_idx, (data, lbs) in enumerate(TrainLoader) :\n",
    "        data   = data.to(device)\n",
    "        lbs = lbs.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss    = criterion(outputs, lbs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += loss.item()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0.\n",
    "        \n",
    "        for X_val_batch, y_val_batch in TestLoader :\n",
    "            X_val_batch = X_val_batch.to(device)\n",
    "            y_val_batch = y_val_batch.to(device)\n",
    "            \n",
    "            y_val_pred = model(X_val_batch)\n",
    "            \n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            \n",
    "            val_epoch_loss += val_loss.item()\n",
    "    \n",
    "    avg_train_loss = float(train_epoch_loss) / len(TrainLoader)\n",
    "    avg_val_loss   = float(val_epoch_loss) / len(TestLoader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: | Train Acc: {avg_train_loss:.4e} | Test Acc: {avg_val_loss:.4e}')\n",
    "    \n",
    "    if avg_val_loss < best_val_loss :\n",
    "        print(\"Saving Model Checkpoint......\")\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), model_checkpoint)\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1057fb",
   "metadata": {},
   "source": [
    "### Constructing AMC Adversarial Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f4917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPS for FGSM attack\n",
    "curr_attack = \"FGSM_Linfinity\"\n",
    "eps_values = np.array([0.000, 0.001, 0.002, 0.003, 0.005, 0.007, \n",
    "                       0.010, 0.020, 0.030])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Current Device: \", device)\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "filename = \"RML2016.10b.dat\"\n",
    "snrs, mods, X, labels = process_data(filename)\n",
    "\n",
    "x_train, x_test, y_train, y_test, test_labels, test_idx = train_test_split(X, labels, mods)\n",
    "\n",
    "train_dataset = TensorDataset(x_train, x_train)\n",
    "test_dataset  = TensorDataset(x_test,  x_test)\n",
    "batch_size = 16\n",
    "TrainLoader = DataLoader(train_dataset, batch_size = batch_size, \n",
    "                         shuffle = False)\n",
    "TestLoader  = DataLoader(test_dataset,  batch_size = batch_size, \n",
    "                         shuffle = False)\n",
    "\n",
    "model = CNN(input_size = 128)\n",
    "model.load_state_dict(torch.load(\"CNN_base.pt\"))\n",
    "model = model.to(device)\n",
    "encoder = AUTOENCODER()\n",
    "encoder.load_state_dict(torch.load(\"AUTOENCODER.pt\"))\n",
    "encoder.to(device)\n",
    "criterion  = nn.MSELoss()\n",
    "\n",
    "T = []\n",
    "for eps in eps_values:\n",
    "    E = []\n",
    "    for batch_idx, (data, lbs) in enumerate(TrainLoader) :\n",
    "        data = data.to(device)\n",
    "        lbs = lbs.to(device)\n",
    "\n",
    "        #FGSM L-infinity Adversarial Retraining\n",
    "        adv_data = FGSM_Linf_attack(model, device, data, labels, eps)\n",
    "\n",
    "        outputs = encoder(adv_data)\n",
    "        loss = criterion(outputs,lbs)\n",
    "        E.append(loss)\n",
    "    \n",
    "    T.append(max(E))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a60c2b",
   "metadata": {},
   "source": [
    "### Applying AMC Adversarial Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = AUTOENCODER()\n",
    "encoder.load_state_dict(torch.load(\"AUTOENCODER.pt\"))\n",
    "encoder.to(device)\n",
    "\n",
    "encoder.eval()\n",
    "\n",
    "dtct_rate = []\n",
    "for i in range(len(eps_values)) \n",
    "    detect_num = 0\n",
    "    all_num = 0\n",
    "    for X_val_batch, y_val_batch in TestLoader :\n",
    "        X_val_batch = X_val_batch.to(device)\n",
    "        y_val_batch = y_val_batch.to(device)\n",
    "        \n",
    "        adv_x = FGSM_Linf_attack(model, device, x_val_batch, y_val_batch, eps)\n",
    "        y_val_pred = encoder(adv_x)\n",
    "        val_loss = criterion(y_val_pred, adv_x)\n",
    "\n",
    "        if val_loss > T:\n",
    "            detect_num += 1\n",
    "        all_num += 1\n",
    "    \n",
    "    detection_rate = float(detect_num) / float(all_num)  \n",
    "    print(f'eps value {eps_values[i]}: Detection rate: {detection_rate:.3f}')   \n",
    "    dtct_rate.append(detection_rate)\n",
    "\n",
    "print(dict_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f35d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
